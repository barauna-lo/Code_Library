{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3saAtENTovNu"
      },
      "source": [
        "### MLP for CIFAR10\n",
        "\n",
        "Multi-Layer Perceptron (MLP) is a simple neural network model that can be used for classification tasks. \n",
        "\n",
        "In this demo, we will train a 3-layer MLP on the CIFAR10 dataset. We will illustrate 2 MLP implementations.\n",
        "\n",
        "Let us first import the required modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-PdAvT2ovN2",
        "outputId": "33197827-1206-43a0-f97d-5a1241a94a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
            "\u001b[K     |████████████████████████████████| 708 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.9.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.12.1+cu113)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.8.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.10.0-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.49.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (3.2.1)\n",
            "Installing collected packages: torchmetrics, pyDeprecate, pytorch-lightning\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.7.7 torchmetrics-0.10.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install wandb\n",
        "#!pip install einops\n",
        "#!pip install argparse\n",
        "#!pip install pytorch_lightning\n",
        "import torch\n",
        "import torchvision\n",
        "import wandb\n",
        "import math\n",
        "from torch import nn\n",
        "from einops import rearrange\n",
        "from argparse import ArgumentParser\n",
        "from pytorch_lightning import LightningModule, Trainer, Callback\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from torchmetrics.functional import accuracy\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heaDASpOovN4"
      },
      "source": [
        "#### MLP using PyTorch `nn.Linear`\n",
        "\n",
        "The most straightforward way to implement an MLP is to use the `nn.Linear` module. In the following code, we implement a 3-layer MLP with GELU activation function. The GELU can be replaced by other activation functions such as RELU.\n",
        "\n",
        "Pls take note of the correct sizes. `fc1` input size is `n_features` which is size of the flattened input `x`. `fc1` output size is `n_hidden` which then becomes the input size of `fc2`. In other words, all input/output sizes up to `fc3` fit together perfectly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kcnrkRFpovN5"
      },
      "outputs": [],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self, n_features=3*32*32, n_hidden=512, num_classes=10):\n",
        "        super().__init__()\n",
        "        # the 3 Linear layers of the MLP\n",
        "        self.fc1 = nn.Linear(n_features, n_hidden)\n",
        "        self.fc2 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.fc3 = nn.Linear(n_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # flatten x - (batch_size, 3, 32, 32) -> (batch_size, 3*32*32)\n",
        "        # ascii art for the case that x is 1 x 2 x 2 (channel, height, width)\n",
        "        # ---------         ----------------- \n",
        "        # | 1 | 2 |    ---> | 1 | 2 | 3 | 4 |\n",
        "        # | 3 | 4 |         -----------------\n",
        "        # ---------\n",
        "        # we can use any of the following methods to flatten the tensor\n",
        "        #y = torch.flatten(x, 1)\n",
        "        #y = x.view(x.size(0), -1)\n",
        "        # but this is the most intuitive since it shows the actual flattening\n",
        "        y = rearrange(x, 'b c h w -> b (c h w)')\n",
        "        y = nn.GELU()(self.fc1(y))\n",
        "        y = nn.GELU()(self.fc2(y))\n",
        "        y = self.fc3(y)\n",
        "        return y\n",
        "        # we dont need to compute softmax since it is already\n",
        "        # built into the CE loss function in PyTorch\n",
        "        #return F.log_softmax(y, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuwzdowjovN7"
      },
      "source": [
        "#### MLP implementation using Tensors\n",
        "\n",
        "In this case, we illustrate how to implement the formula of an MLP layer using weights and biases. Note that if we remove the initialization of the weights and biases, the model will not converge. In the previous example, `Linear` automatically performs the weights and biases initialization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bbBjXExUovN8"
      },
      "outputs": [],
      "source": [
        "class TensorMLP(nn.Module):\n",
        "    def __init__(self, n_features=3*32*32, n_hidden=512, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # weights and biases for layer 1\n",
        "        self.w1 = nn.Parameter(torch.empty((n_hidden, n_features)))\n",
        "        self.b1 = nn.Parameter(torch.empty((n_hidden,)))\n",
        "\n",
        "         # weights and biases for layer 2\n",
        "        self.w2 = nn.Parameter(torch.empty((n_hidden, n_hidden)))\n",
        "        self.b2 = nn.Parameter(torch.empty((n_hidden,)))\n",
        "\n",
        "         # weights and biases for layer 3\n",
        "        self.w3 = nn.Parameter(torch.empty((num_classes, n_hidden)))\n",
        "        self.b3 = nn.Parameter(torch.empty((num_classes,)))\n",
        "\n",
        "        # initialize parameters manually bec we implemented the linear layer manually\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # we use Kaiming initializer for weights\n",
        "        nn.init.kaiming_uniform_(self.w1, a=math.sqrt(5))\n",
        "        # zero for biases\n",
        "        nn.init.constant_(self.b1, 0)\n",
        "        nn.init.kaiming_uniform_(self.w2, a=math.sqrt(5))\n",
        "        nn.init.constant_(self.b2, 0)\n",
        "        nn.init.kaiming_uniform_(self.w3, a=math.sqrt(5))\n",
        "        nn.init.constant_(self.b3, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # flatten\n",
        "        y = rearrange(x, 'b c h w -> b (c h w)')\n",
        "        # we manually compute the output of each layer\n",
        "        y = y @ self.w1.T + self.b1\n",
        "        y = nn.GELU()(y)\n",
        "        y = y @ self.w2.T + self.b2\n",
        "        y = nn.GELU()(y)\n",
        "        y = y @ self.w3.T + self.b3\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DouTTrSsovN-"
      },
      "source": [
        "#### PyTorch Lightning Module for MLP\n",
        "\n",
        "This is the PL module so we can easily change the implementation of the MLP and compare the results.  More detailed results can be found on the `wandb.ai` page.\n",
        "\n",
        "Using `model` parameter, we can easily switch between the two MLP implementations shown above. We also benchmark the result using a ResNet18 model. The rest of the code is similar to our PL module example for MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G0_hQOCpovN_"
      },
      "outputs": [],
      "source": [
        "class LitCIFAR10Model(LightningModule):\n",
        "    def __init__(self, num_classes=10, lr=0.001, batch_size=64,\n",
        "                 num_workers=4, max_epochs=30,\n",
        "                 model=SimpleMLP):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.model = model(num_classes=num_classes)\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    # this is called during fit()\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.forward(x)\n",
        "        loss = self.loss(y_hat, y)\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    # calls to self.log() are recorded in wandb\n",
        "    def training_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "        self.log(\"train_loss\", avg_loss, on_epoch=True)\n",
        "\n",
        "    # this is called at the end of an epoch\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.forward(x)\n",
        "        loss = self.loss(y_hat, y)\n",
        "        acc = accuracy(y_hat, y) * 100.\n",
        "        # we use y_hat to display predictions during callback\n",
        "        return {\"y_hat\": y_hat, \"test_loss\": loss, \"test_acc\": acc}\n",
        "\n",
        "    # this is called at the end of all epochs\n",
        "    def test_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
        "        avg_acc = torch.stack([x[\"test_acc\"] for x in outputs]).mean()\n",
        "        self.log(\"test_loss\", avg_loss, on_epoch=True, prog_bar=True)\n",
        "        self.log(\"test_acc\", avg_acc, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    # validation is the same as test\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "       return self.test_step(batch, batch_idx)\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        return self.test_epoch_end(outputs)\n",
        "\n",
        "    # we use Adam optimizer\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = Adam(self.parameters(), lr=self.hparams.lr)\n",
        "        # this decays the learning rate to 0 after max_epochs using cosine annealing\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs)\n",
        "        return [optimizer], [scheduler]\n",
        "    \n",
        "    # this is called after model instatiation to initiliaze the datasets and dataloaders\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataloader()\n",
        "        self.test_dataloader()\n",
        "\n",
        "    # build train and test dataloaders using MNIST dataset\n",
        "    # we use simple ToTensor transform\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            torchvision.datasets.CIFAR10(\n",
        "                \"./data\", train=True, download=True, \n",
        "                transform=torchvision.transforms.ToTensor()\n",
        "            ),\n",
        "            batch_size=self.hparams.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.hparams.num_workers,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            torchvision.datasets.CIFAR10(\n",
        "                \"./data\", train=False, download=True, \n",
        "                transform=torchvision.transforms.ToTensor()\n",
        "            ),\n",
        "            batch_size=self.hparams.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.hparams.num_workers,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.test_dataloader()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6DfOmGYovOB"
      },
      "source": [
        "#### Arguments\n",
        "\n",
        "Please change the `--model` argument to switch between the different models to be used as CIFAR10 classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Aabjp7-6ovOD"
      },
      "outputs": [],
      "source": [
        "def get_args():\n",
        "    parser = ArgumentParser(description=\"PyTorch Lightning MNIST Example\")\n",
        "    parser.add_argument(\"--max-epochs\", type=int, default=30, help=\"num epochs\")\n",
        "    parser.add_argument(\"--batch-size\", type=int, default=64, help=\"batch size\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=0.001, help=\"learning rate\")\n",
        "\n",
        "    parser.add_argument(\"--num-classes\", type=int, default=10, help=\"num classes\")\n",
        "\n",
        "    parser.add_argument(\"--devices\", default=1)\n",
        "    parser.add_argument(\"--accelerator\", default='gpu')\n",
        "    parser.add_argument(\"--num-workers\", type=int, default=4, help=\"num workers\")\n",
        "    \n",
        "    #parser.add_argument(\"--model\", default=torchvision.models.resnet18)\n",
        "    #parser.add_argument(\"--model\", default=TensorMLP)\n",
        "    parser.add_argument(\"--model\", default=SimpleMLP)\n",
        "    args = parser.parse_args(\"\")\n",
        "    return args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TNhu90oovOE"
      },
      "source": [
        "#### Weights and Biases Callback\n",
        "\n",
        "The callback logs train and validation metrics to `wandb`. It also logs sample predictions. This is similar to our `WandbCallback` example for MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yPIBJLY1ovOE"
      },
      "outputs": [],
      "source": [
        "class WandbCallback(Callback):\n",
        "\n",
        "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
        "        # process first 10 images of the first batch\n",
        "        if batch_idx == 0:\n",
        "            label_human = [\"airplane\", \"automobile\", \"bird\", \"cat\",\n",
        "                           \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "            n = 10\n",
        "            x, y = batch\n",
        "            outputs = outputs[\"y_hat\"]\n",
        "            outputs = torch.argmax(outputs, dim=1)\n",
        "            # log image, ground truth and prediction on wandb table\n",
        "            columns = ['image', 'ground truth', 'prediction']\n",
        "            data = [[wandb.Image(x_i), label_human[y_i], label_human[y_pred]] for x_i, y_i, y_pred in list(\n",
        "                zip(x[:n], y[:n], outputs[:n]))]\n",
        "            wandb_logger.log_table(\n",
        "                key=pl_module.model.__class__.__name__,\n",
        "                columns=columns,\n",
        "                data=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqlrHraGovOE"
      },
      "source": [
        "#### Training and Validation of Different Models\n",
        "\n",
        "The validation accuracy of both MLP model implmentations are almost the same at `~53%`. This shows that the 2 MLP implementations are almost the same.\n",
        "\n",
        "Meanwhile the ResNet18 model has accuracy of `~78%`. The MLP model has still a long way to go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "9550828d54de45ddb93762b563f99deb",
            "1ddeabc5e24d47809dfecc16f7abc2ff",
            "1866d608dc604b63afc21ea8622450f1",
            "18c7b77654114d7589addf4df6d39c18",
            "0d1df6ccdbd64f1b95a2be06936e3225",
            "9018dbaba82940acbd85fd06cb574990",
            "c5d66a35bb094ab783075a3e3ca6e6b9",
            "20f740a8c5c748cfaf0c3e6f5c0be7e9",
            "18c97bcf63ce4e53b365f67015d070fd",
            "a08e4e84f1e9455dac9236d061b086d7",
            "5edb31e446bb4bcb936b87d9200963fd"
          ]
        },
        "id": "Q5z3vtjWovOF",
        "outputId": "4fa37bd8-c9db-40c3-ba56-43d841c08c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9550828d54de45ddb93762b563f99deb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "LitCIFAR10Model(\n",
            "  (model): SimpleMLP(\n",
            "    (fc1): Linear(in_features=3072, out_features=512, bias=True)\n",
            "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            "  (loss): CrossEntropyLoss()\n",
            ")\n",
            "SimpleMLP\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    args = get_args()\n",
        "    model = LitCIFAR10Model(num_classes=args.num_classes,\n",
        "                           lr=args.lr, batch_size=args.batch_size,\n",
        "                           num_workers=args.num_workers,\n",
        "                           model=args.model,)\n",
        "    model.setup()\n",
        "\n",
        "    # printing the model is useful for debugging\n",
        "    print(model)\n",
        "    print(model.model.__class__.__name__)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "pl_2oqjnovOF",
        "outputId": "f68294a4-c11c-4716-a94c-5f2e98994738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "    # wandb is a great way to debug and visualize this model\n",
        "    wandb_logger = WandbLogger(project=\"mlp-cifar\")\n",
        "    \n",
        "    trainer = Trainer(accelerator=args.accelerator,\n",
        "                      devices=args.devices,\n",
        "                      max_epochs=args.max_epochs,\n",
        "                      logger=wandb_logger,\n",
        "                      callbacks=[WandbCallback()])\n",
        "    trainer.fit(model)\n",
        "    trainer.test(model)\n",
        "\n",
        "    wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "52772734322c44a04e342c358be70f2ff4d97da358cb3cd38ceb0f6066598be5"
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9550828d54de45ddb93762b563f99deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ddeabc5e24d47809dfecc16f7abc2ff",
              "IPY_MODEL_1866d608dc604b63afc21ea8622450f1",
              "IPY_MODEL_18c7b77654114d7589addf4df6d39c18"
            ],
            "layout": "IPY_MODEL_0d1df6ccdbd64f1b95a2be06936e3225"
          }
        },
        "1ddeabc5e24d47809dfecc16f7abc2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9018dbaba82940acbd85fd06cb574990",
            "placeholder": "​",
            "style": "IPY_MODEL_c5d66a35bb094ab783075a3e3ca6e6b9",
            "value": "100%"
          }
        },
        "1866d608dc604b63afc21ea8622450f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f740a8c5c748cfaf0c3e6f5c0be7e9",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18c97bcf63ce4e53b365f67015d070fd",
            "value": 170498071
          }
        },
        "18c7b77654114d7589addf4df6d39c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a08e4e84f1e9455dac9236d061b086d7",
            "placeholder": "​",
            "style": "IPY_MODEL_5edb31e446bb4bcb936b87d9200963fd",
            "value": " 170498071/170498071 [00:04&lt;00:00, 43858951.83it/s]"
          }
        },
        "0d1df6ccdbd64f1b95a2be06936e3225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9018dbaba82940acbd85fd06cb574990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5d66a35bb094ab783075a3e3ca6e6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20f740a8c5c748cfaf0c3e6f5c0be7e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18c97bcf63ce4e53b365f67015d070fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a08e4e84f1e9455dac9236d061b086d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5edb31e446bb4bcb936b87d9200963fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}